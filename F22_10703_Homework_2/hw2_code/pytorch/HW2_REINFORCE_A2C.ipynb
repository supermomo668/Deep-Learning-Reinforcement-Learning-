{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odNaDE1zyrL2"
   },
   "source": [
    "# install dependancies, takes around 45 seconds\n",
    "\n",
    "Rendering Dependancies\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "8-AxnvAVyzQQ"
   },
   "source": [
    "#remove \" > /dev/null 2>&1\" to see what is going on under the hood\n",
    "#!pip install gym pyvirtualdisplay 2>&1\n",
    "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8A-1LTSH88EE"
   },
   "source": [
    "Pacman Dependancies"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "TCelFzWY9MBI",
    "outputId": "6f32734e-4791-49d0-c7c9-1ac7853ee167"
   },
   "source": [
    "# !apt-get update > /dev/null 2>&1\n",
    "# !apt-get install cmake > /dev/null 2>&1\n",
    "!pip install --upgrade setuptools 2>&1\n",
    "!pip install ez_setup > /dev/null 2>&1\n",
    "!pip install gym[atari] > /dev/null 2>&1\n",
    "!pip install gym[classic_control]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APXSx7hg19TH"
   },
   "source": [
    "# Imports and Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OtnCDULP74i1"
   },
   "outputs": [],
   "source": [
    "import sys, os, copy\n",
    "from pathlib import Path\n",
    "proj_folder = Path('.').absolute()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nQEtc28G4niA",
    "outputId": "eb9d76c5-7e1f-441f-b2ec-70fa69fcfb98"
   },
   "source": [
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "G9UWeToN4r7D"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility functions to enable video recording of gym environment and displaying it\n",
    "To enable video, just do \"env = wrap_env(env)\"\"\n",
    "\"\"\"\n",
    "def show_video():\n",
    "    mp4list = glob.glob('video/*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                    loop controls style=\"height: 400px;\">\n",
    "                    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "                 </video>'''.format(encoded.decode('ascii'))))\n",
    "    else: \n",
    "        print(\"Could not find video\")\n",
    "    \n",
    "\n",
    "def wrap_env(env, save_path=proj_folder/'video'):\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "    env = record_video.RecordVideo(env, proj_folder/'video', name_prefix='eval')\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3BGbWOu179M"
   },
   "source": [
    "# Run Simulations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Ys9oSdMk7e64"
   },
   "outputs": [],
   "source": [
    "import numpy as np, torch, gym\n",
    "import torch.nn.functional as F\n",
    "from gym.wrappers import record_video\n",
    "#from gym.utils.save_video import save_video\n",
    "#\n",
    "from gym import logger as gymlogger\n",
    "from pyvirtualdisplay import Display\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "global DEBUG\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEBUG=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "cdEOSetG7h0L"
   },
   "outputs": [],
   "source": [
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, activation, layers=[32,32,16]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(input_size, layers[0])\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(layers[0], layers[1])\n",
    "        self.activation2 = torch.nn.ReLU()\n",
    "        self.linear3 = torch.nn.Linear(layers[1], layers[2])\n",
    "        self.activation3 = torch.nn.ReLU()\n",
    "\n",
    "        self.output_layer = torch.nn.Linear(layers[2], output_size)\n",
    "        self.output_activation = activation\n",
    "\n",
    "        #initialize weights, following 'fan_avg' approach\n",
    "        torch.nn.init.xavier_normal_(self.linear1.weight)\n",
    "        torch.nn.init.xavier_normal_(self.linear2.weight)\n",
    "        torch.nn.init.xavier_normal_(self.linear3.weight)\n",
    "        torch.nn.init.xavier_normal_(self.output_layer.weight)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.activation1(self.linear1(inputs))\n",
    "        x = self.activation2(self.linear2(x))\n",
    "        x = self.activation3(self.linear3(x))\n",
    "        x = self.output_activation(self.output_layer(x))\n",
    "        return x\n",
    "\n",
    "    def fit(self, loss, optimizer):\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "class A2C(object):\n",
    "    # Implementation of N-step Advantage Actor Critic.\n",
    "\n",
    "    def __init__(self, actor, actor_lr, N, nA, critic, critic_lr, baseline=False, a2c=True):\n",
    "        # Note: baseline is true if we use reinforce with baseline\n",
    "        #       a2c is true if we use a2c else reinforce\n",
    "        \n",
    "        # TODO: Initializes A2C.\n",
    "        self.type = \"A2C\" if a2c else (\"Baseline\" if baseline else \"Reinforce\")  # Pick one of: \"A2C\", \"Baseline\", \"Reinforce\"\n",
    "        \n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        actor.to(device)\n",
    "        # define meta variabless\n",
    "        self.save_dir = Path('./').absolute()/'Output'\n",
    "        if self.type == \"A2C\":\n",
    "            critic.to(device)\n",
    "            self.critic_optimizer = torch.optim.Adam(critic.parameters(), lr=critic_lr)\n",
    "        elif self.type == \"Baseline\":\n",
    "            pass\n",
    "        else:\n",
    "            # Reinforce\n",
    "            pass\n",
    "        self.actor = actor\n",
    "        self.actor_optimizer = torch.optim.Adam(actor.parameters(), lr=actor_lr)\n",
    "        self.N = N\n",
    "        assert self.type is not None, \"Type must be provided\"\n",
    "\n",
    "    def reinforce_criterion(self, y_pred, y_true):\n",
    "        log_y_pred = torch.log(y_pred)   # log probability of ation\n",
    "        l = torch.multiply(log_y_pred, y_true)   # (n_eps, nA)\n",
    "        l_action = torch.sum(l, axis=1)  # (n_eps,)\n",
    "        return torch.mean(l_action)\n",
    "    \n",
    "    def fit_actor(self, states, G_total, epochs=1, batch_size=1):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.actor.train()\n",
    "        n_example = len(states)\n",
    "        history = dict.fromkeys(['loss'],[])\n",
    "        for e in range(epochs):\n",
    "            for i in range(int(np.ceil(len(states)/batch_size))):\n",
    "                start_idx, end_idx = batch_size*i, min(batch_size*(i+1), n_example)\n",
    "                states_, target_ = states[start_idx: end_idx], G_total[start_idx: end_idx]\n",
    "                pred_G = self.actor(states_.cuda())\n",
    "                loss = self.reinforce_criterion(pred_G, target_.cuda())\n",
    "                # # measure metrics and record loss\n",
    "                # m1 = metric1(cls_out.cpu(), target)\n",
    "                # m2 = metric2(cls_out.cpu(), target)\n",
    "                history['loss'].append(loss)\n",
    "                self.actor_optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.actor_optimizer.step()\n",
    "                if DEBUG: print(f\"Latest Loss:{history['loss'][-1]}\")\n",
    "        return history\n",
    "\n",
    "    def evaluate_policy(self, env, render=True):\n",
    "        # TODO: Compute Accumulative trajectory reward(set a trajectory length threshold if you want)\n",
    "        \"\"\" compute rewards\n",
    "        \"\"\"\n",
    "        self.actor.eval()\n",
    "        _, _, r, _ = self.generate_episode(env, render=render)\n",
    "        rtot = np.sum(np.array(r))\n",
    "        return rtot\n",
    "\n",
    "    def generate_episode(self, env, render=False):\n",
    "        \"\"\"\n",
    "\t\t# Generates an episode by executing the current policy in the given env.\n",
    "\t\t# Returns:\n",
    "\t\t# - a list of states, indexed by time step\n",
    "            shape: (t)\n",
    "\t\t# - a list of actions, indexed by time step\n",
    "            shape: (t, nA)\n",
    "\t\t# - a list of rewards, indexed by time step\n",
    "            shape: (t)\n",
    "        \"\"\"\n",
    "        states, actions, rewards, actions_probs=[], [] ,[], []\n",
    "        # \n",
    "        nS = env.observation_space.shape[0]\n",
    "        nA = env.action_space.n\n",
    "\t\t# Start episode\n",
    "        states.append(np.expand_dims(env.reset(), axis=0))\n",
    "        terminal = False\n",
    "        cts = 0\n",
    "        while not terminal:\n",
    "            cts+=1\n",
    "            if render: \n",
    "                env.unwrapped.render(mode='rgb_array')    # env.render(mode='rgb_array')\n",
    "                #env.capture_frame()\n",
    "            ac = self.actor(torch.Tensor(states[-1]).to(device)).squeeze(0)   # ensure [nA] vector\n",
    "            if DEBUG: print(f\"Input state:{states[-1]}\\nOutput action:{ac}\")\n",
    "            ac_prob = ac.detach().cpu().numpy().flatten()\n",
    "            ac_prob = np.nan_to_num(ac_prob,0)\n",
    "            #\n",
    "            a_ = np.random.choice(ac_prob, p=ac_prob)   # stochastic choice\n",
    "            curr_ac = np.where(ac_prob==a_)[0][0]  # Current Action\n",
    "            action_OH = np.eye(nA)[curr_ac]  # one-hot action\n",
    "            \n",
    "            # move in direction and get environment output\n",
    "            s, r, terminal, _ = env.step(curr_ac)\n",
    "            # add to history\n",
    "            states.append(np.expand_dims(s, axis=0))\n",
    "            actions.append(action_OH)\n",
    "            actions_probs.append(ac_prob)\n",
    "            rewards.append(r)\n",
    "            curr_state = copy.deepcopy(s)\n",
    "        if DEBUG: print(f\"action probs:{ac_prob}\\nfinal action:{action_OH}\")\n",
    "        print(\"Finished after {} timesteps\".format(cts+1))\n",
    "        env.close()\n",
    "\t\t# flatten \n",
    "        states=np.reshape(np.array(states), (-1, nS))\n",
    "        actions=np.reshape(np.array(actions), (-1, nA))\n",
    "        return np.stack(states), np.stack(actions), np.stack(rewards), np.stack(actions_probs)\n",
    "\n",
    "    def train(self, env, gamma=0.99, n=10):\n",
    "        \"\"\"\n",
    "        # Trains the model on a single episode using REINFORCE or A2C/A3C.\n",
    "        params:\n",
    "            n: number of n-steps look ahead\n",
    "        \"\"\"\n",
    "        # TODO: Implement this method. It may be helpful to call the class\n",
    "        #       method generate_episode() to generate training data.\n",
    "        eps_lim = 500    # length of episode 'limit'\n",
    "        batch_size_ratio = 1    # portion of length of states to feed in NN\n",
    "        alpha = 1e-2\n",
    "        assert 0<batch_size_ratio<=1, \"Batch size between 0 and 1\"\n",
    "        #\n",
    "        env = wrap_env(env)\n",
    "        mean_total, std_total = [], []\n",
    "        # generate episode\n",
    "        states, actions, rewards, actions_prob = self.generate_episode(env, render=False)\n",
    "        states = states[:-1]   # remove the last state\n",
    "        # get discounted reward vector\n",
    "            # [sum : r*gamma*0...r*gamma*n]\n",
    "        G_tot=[0]\n",
    "        for n_gamma, r in enumerate(reversed(rewards)):\n",
    "            # insert from last reward to beginning \n",
    "            G_tot.insert(0, r+gamma**n_gamma*G_tot[0])\n",
    "        if DEBUG: print(f\"Sum of Expected Rewards G:{G_tot}\")\n",
    "        G_tot=np.array(G_tot[:-1])\n",
    "        # weight actions by rewards and fit model\n",
    "        if DEBUG: print(f\"G_tot:[{len(G_tot)}], actions:[{len(actions)}], states:[{len(states)}]\")\n",
    "        G_total_actions = np.multiply(G_tot, actions.T).T   # (t, nA)\n",
    "        train_history = self.fit_actor(torch.Tensor(states), torch.Tensor(G_total_actions*alpha), epochs=1, batch_size=int(len(states)*batch_size_ratio))\n",
    "        return train_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqrh5P-cCbe3"
   },
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "xKD2PlR3WJii"
   },
   "outputs": [],
   "source": [
    "import argparse, matplotlib.pyplot as plt, tqdm\n",
    "def parse_a2c_arguments():\n",
    "    # Command-line flags are defined here.\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--env-name', dest='env_name', type=str,\n",
    "                        default='CartPole-v0', help=\"Name of the environment to be run.\")   # 'LunarLander-v2'\n",
    "    parser.add_argument('--num-episodes', dest='num_episodes', type=int,\n",
    "                        default=20, help=\"Number of episodes to train on.\")    # 3500\n",
    "    parser.add_argument('--lr', dest='lr', type=float,\n",
    "                        default=5e-4, help=\"The actor's learning rate.\")\n",
    "    parser.add_argument('--baseline-lr', dest='baseline_lr', type=float,\n",
    "                        default=5e-4, help=\"The actor's learning rate.\")\n",
    "    parser.add_argument('--critic-lr', dest='critic_lr', type=float,\n",
    "                        default=1e-4, help=\"The critic's learning rate.\")\n",
    "    parser.add_argument('--n', dest='n', type=int,\n",
    "                        default=100, help=\"The value of N in N-step A2C.\")\n",
    "\n",
    "    parser_group = parser.add_mutually_exclusive_group(required=False)\n",
    "    parser_group.add_argument('--render', dest='render',\n",
    "                              action='store_true',\n",
    "                              help=\"Whether to render the environment.\")\n",
    "    parser_group.add_argument('--no-render', dest='render',\n",
    "                              action='store_false',\n",
    "                              help=\"Whether to render the environment.\")\n",
    "    parser.set_defaults(render=False)\n",
    "\n",
    "    return parser.parse_known_args()[0]    #.parse_args()\n",
    "args = parse_a2c_arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Zj2YirE8nIB",
    "outputId": "e4a6e959-5eab-4606-9037-887c8f73b36f",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurations:Namespace(baseline_lr=0.0005, critic_lr=0.0001, env_name='CartPole-v0', lr=0.0005, n=100, num_episodes=20, render=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0\n",
      "Finished after 25 timesteps\n",
      "[Policy Evaluation]\n",
      "Finished after 16 timesteps\n",
      "Finished after 24 timesteps\n",
      "Finished after 20 timesteps\n",
      "Finished after 23 timesteps\n",
      "Finished after 27 timesteps\n",
      "Finished after 15 timesteps\n",
      "Finished after 13 timesteps\n",
      "Finished after 15 timesteps\n",
      "Finished after 22 timesteps\n",
      "Finished after 15 timesteps\n",
      "Finished after 15 timesteps\n",
      "Finished after 21 timesteps\n",
      "Finished after 11 timesteps\n",
      "Finished after 17 timesteps\n",
      "Finished after 13 timesteps\n",
      "Finished after 17 timesteps\n",
      "Finished after 30 timesteps\n",
      "Finished after 19 timesteps\n",
      "Finished after 16 timesteps\n",
      "Finished after 10 timesteps\n",
      "The test reward for episode 0 is 16.95 with sd of 5.123231402152356.\n",
      "Episode: 1\n",
      "Finished after 33 timesteps\n",
      "Episode: 2\n",
      "Finished after 23 timesteps\n",
      "Episode: 3\n",
      "Finished after 15 timesteps\n",
      "Episode: 4\n",
      "Finished after 14 timesteps\n",
      "Episode: 5\n",
      "Finished after 13 timesteps\n",
      "Episode: 6\n",
      "Finished after 15 timesteps\n",
      "Episode: 7\n",
      "Finished after 11 timesteps\n",
      "Episode: 8\n",
      "Finished after 12 timesteps\n",
      "Episode: 9\n",
      "Finished after 42 timesteps\n",
      "Episode: 10\n",
      "Finished after 18 timesteps\n",
      "[Policy Evaluation]\n",
      "Finished after 18 timesteps\n",
      "Finished after 58 timesteps\n",
      "Finished after 40 timesteps\n",
      "Finished after 44 timesteps\n",
      "Finished after 44 timesteps\n",
      "Finished after 14 timesteps\n",
      "Finished after 11 timesteps\n",
      "Finished after 25 timesteps\n",
      "Finished after 18 timesteps\n",
      "Finished after 11 timesteps\n",
      "Finished after 27 timesteps\n",
      "Finished after 18 timesteps\n",
      "Finished after 17 timesteps\n",
      "Finished after 13 timesteps\n",
      "Finished after 18 timesteps\n",
      "Finished after 12 timesteps\n",
      "Finished after 12 timesteps\n",
      "Finished after 12 timesteps\n",
      "Finished after 36 timesteps\n",
      "Finished after 18 timesteps\n",
      "The test reward for episode 10 is 22.3 with sd of 13.37198564163154.\n",
      "Episode: 11\n",
      "Finished after 16 timesteps\n",
      "Episode: 12\n",
      "Finished after 60 timesteps\n",
      "Episode: 13\n",
      "Finished after 33 timesteps\n",
      "Episode: 14\n",
      "Finished after 19 timesteps\n",
      "Episode: 15\n",
      "Finished after 63 timesteps\n",
      "Episode: 16\n",
      "Finished after 19 timesteps\n",
      "Episode: 17\n",
      "Finished after 24 timesteps\n",
      "Episode: 18\n",
      "Finished after 22 timesteps\n",
      "Episode: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 1/1 [00:27<00:00, 27.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished after 46 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#def main_a2c(args):\n",
    "# Parse command-line arguments.\n",
    "env_name = args.env_name\n",
    "\n",
    "# Create the environment.\n",
    "env =  wrap_env(gym.make(env_name))\n",
    "nA = env.action_space.n\n",
    "nS = env.observation_space.shape[0]\n",
    "print(f\"Configurations:{args}\")\n",
    "\n",
    "# Plot average performance of 5 trials\n",
    "num_seeds = 1   # 5\n",
    "eval_freq = 10  # 100\n",
    "l = args.num_episodes//eval_freq\n",
    "res = np.zeros((num_seeds, l))\n",
    "\n",
    "gamma = 0.99\n",
    "act_layer = torch.nn.Softmax(dim=1) \n",
    "for i in tqdm.tqdm(range(num_seeds)):\n",
    "    reward_means = []\n",
    "\n",
    "    # TODO: create networks and setup reinforce/a2c\n",
    "    history = dict.fromkeys(['train','test'],[])\n",
    "    actor = NeuralNet(input_size=nS, output_size=nA, activation=act_layer)\n",
    "    critic = NeuralNet(input_size=nS, output_size=nA, activation=act_layer)\n",
    "    A2C_net = A2C(actor=actor, actor_lr=args.lr, N=args.n, nA=nA, \n",
    "                critic=critic, critic_lr=args.critic_lr, baseline=False, a2c=False)\n",
    "    for m in range(args.num_episodes):\n",
    "        print(\"Episode: {}\".format(m))\n",
    "        history['train'].append(A2C_net.train(env, gamma=gamma))\n",
    "        if m % eval_freq == 0:\n",
    "            print(\"[Policy Evaluation]\")\n",
    "            G = np.zeros(20)   # save 20 iterations of evaluation \n",
    "            for k in range(20):\n",
    "                g = A2C_net.evaluate_policy(env, render=True if k==19 else False)\n",
    "                G[k] = g\n",
    "            reward_mean = G.mean()\n",
    "            reward_sd = G.std()\n",
    "            print(\"The test reward for episode {0} is {1} with sd of {2}.\".format(m, reward_mean, reward_sd))\n",
    "            reward_means.append(reward_mean)\n",
    "            history['test'].append(G)\n",
    "    res[i] = np.array(reward_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x136d26d3df0>,\n",
       " <matplotlib.lines.Line2D at 0x136d26d3430>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ks = np.arange(l)*100\n",
    "avs = np.mean(res, axis=0)\n",
    "maxs = np.max(res, axis=0)\n",
    "mins = np.min(res, axis=0)\n",
    "\n",
    "plt.fill_between(ks, mins, maxs, alpha=0.1)\n",
    "plt.plot(ks, avs, '-o', markersize=1)\n",
    "\n",
    "plt.xlabel('Episode', fontsize = 15)\n",
    "plt.ylabel('Return', fontsize = 15)\n",
    "\n",
    "if not os.path.exists('./plots'):\n",
    "    os.mkdir('./plots')\n",
    "\n",
    "if A2C_net.type == 'A2C':\n",
    "    plt.title(\"A2C Learning Curve for N = {}\".format(args.n), fontsize = 24)\n",
    "    plt.savefig(\"./plots/a2c_curve_N={}.png\".format(args.n))\n",
    "elif A2C_net.type == 'Baseline':\n",
    "    plt.title(\"Baseline Reinforce Learning Curve\".format(args.n), fontsize = 24)\n",
    "    plt.savefig(\"./plots/Baseline_Reinforce_curve.png\".format(args.n))\n",
    "else: # Reinforce\n",
    "    plt.title(\"Reinforce Learning Curve\", fontsize = 24)\n",
    "    plt.savefig(\"./plots/Reinforce_curve.png\")\n",
    "plt.plot(res)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python [conda env:ptml]",
   "language": "python",
   "name": "conda-env-ptml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
