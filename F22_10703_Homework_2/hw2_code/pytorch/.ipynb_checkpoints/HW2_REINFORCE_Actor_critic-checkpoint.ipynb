{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odNaDE1zyrL2"
   },
   "source": [
    "# install dependancies, takes around 45 seconds\n",
    "\n",
    "Rendering Dependancies\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "8-AxnvAVyzQQ"
   },
   "source": [
    "#remove \" > /dev/null 2>&1\" to see what is going on under the hood\n",
    "#!pip install gym pyvirtualdisplay 2>&1\n",
    "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8A-1LTSH88EE"
   },
   "source": [
    "Pacman Dependancies"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "TCelFzWY9MBI",
    "outputId": "6f32734e-4791-49d0-c7c9-1ac7853ee167"
   },
   "source": [
    "# !apt-get update > /dev/null 2>&1\n",
    "# !apt-get install cmake > /dev/null 2>&1\n",
    "!pip install --upgrade setuptools 2>&1\n",
    "!pip install ez_setup > /dev/null 2>&1\n",
    "!pip install gym[atari] > /dev/null 2>&1\n",
    "!pip install gym[classic_control]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APXSx7hg19TH"
   },
   "source": [
    "# Imports and Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OtnCDULP74i1"
   },
   "outputs": [],
   "source": [
    "import sys, os, copy\n",
    "from pathlib import Path\n",
    "proj_folder = Path('.').absolute()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nQEtc28G4niA",
    "outputId": "eb9d76c5-7e1f-441f-b2ec-70fa69fcfb98"
   },
   "source": [
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "G9UWeToN4r7D"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility functions to enable video recording of gym environment and displaying it\n",
    "To enable video, just do \"env = wrap_env(env)\"\"\n",
    "\"\"\"\n",
    "def show_video():\n",
    "    mp4list = glob.glob('video/*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                    loop controls style=\"height: 400px;\">\n",
    "                    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "                 </video>'''.format(encoded.decode('ascii'))))\n",
    "    else: \n",
    "        print(\"Could not find video\")\n",
    "    \n",
    "\n",
    "def wrap_env(env, save_path=proj_folder/'video'):\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "    env = record_video.RecordVideo(env, proj_folder/'video', name_prefix='train')\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3BGbWOu179M"
   },
   "source": [
    "# Run Simulations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ys9oSdMk7e64"
   },
   "outputs": [],
   "source": [
    "import numpy as np, torch, gym\n",
    "import torch.nn.functional as F\n",
    "from gym.wrappers import record_video\n",
    "#\n",
    "from gym import logger as gymlogger\n",
    "from pyvirtualdisplay import Display\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "global DEBUG\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEBUG=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cdEOSetG7h0L"
   },
   "outputs": [],
   "source": [
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, activation, layers=[32,32,16]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(input_size, layers[0])\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(layers[0], layers[1])\n",
    "        self.activation2 = torch.nn.ReLU()\n",
    "        self.linear3 = torch.nn.Linear(layers[1], layers[2])\n",
    "        self.activation3 = torch.nn.ReLU()\n",
    "\n",
    "        self.output_layer = torch.nn.Linear(layers[2], output_size)\n",
    "        self.output_activation = activation\n",
    "\n",
    "        #initialize weights, following 'fan_avg' approach\n",
    "        torch.nn.init.xavier_normal_(self.linear1.weight)\n",
    "        torch.nn.init.xavier_normal_(self.linear2.weight)\n",
    "        torch.nn.init.xavier_normal_(self.linear3.weight)\n",
    "        torch.nn.init.xavier_normal_(self.output_layer.weight)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.activation1(self.linear1(inputs))\n",
    "        x = self.activation2(self.linear2(x))\n",
    "        x = self.activation3(self.linear3(x))\n",
    "        x = self.output_activation(self.output_layer(x))\n",
    "        return x\n",
    "\n",
    "    def fit(self, loss, optimizer):\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "class A2C(object):\n",
    "    # Implementation of N-step Advantage Actor Critic.\n",
    "\n",
    "    def __init__(self, actor, actor_lr, N, nA, critic, critic_lr, baseline=False, a2c=True):\n",
    "        # Note: baseline is true if we use reinforce with baseline\n",
    "        #       a2c is true if we use a2c else reinforce\n",
    "        \n",
    "        # TODO: Initializes A2C.\n",
    "        self.type = \"A2C\" if a2c else (\"Baseline\" if baseline else \"Reinforce\")  # Pick one of: \"A2C\", \"Baseline\", \"Reinforce\"\n",
    "        \n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        actor.to(device)\n",
    "        # define meta variabless\n",
    "        self.save_dir = Path('./').absolute()/'Output'\n",
    "        if self.type == \"A2C\":\n",
    "            critic.to(device)\n",
    "            self.critic_optimizer = torch.optim.Adam(critic.parameters(), lr=critic_lr)\n",
    "        elif self.type == \"Baseline\":\n",
    "            pass\n",
    "        else:\n",
    "            # Reinforce\n",
    "            pass\n",
    "        self.actor = actor\n",
    "        self.actor_optimizer = torch.optim.Adam(actor.parameters(), lr=actor_lr)\n",
    "        self.N = N\n",
    "        assert self.type is not None, \"Type must be provided\"\n",
    "\n",
    "    def reinforce_criterion(self, y_pred, y_true):\n",
    "        log_y_pred = torch.log(y_pred)   # log probability of ation\n",
    "        l = torch.multiply(log_y_pred, y_true)   # (n_eps, nA)\n",
    "        l_action = torch.sum(l, axis=1)  # (n_eps,)\n",
    "        return torch.mean(l_action)\n",
    "    \n",
    "    def fit_actor(self, states, G_total, epochs=1, batch_size=1):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.actor.train()\n",
    "        n_example = len(states)\n",
    "        history = dict.fromkeys(['loss'],[])\n",
    "        for e in range(epochs):\n",
    "            for i in range(int(np.ceil(len(states)/batch_size))):\n",
    "                start_idx, end_idx = batch_size*i, min(batch_size*(i+1), n_example)\n",
    "                states_, target_ = states[start_idx: end_idx], G_total[start_idx: end_idx]\n",
    "                pred_G = self.actor(states_.cuda())\n",
    "                loss = self.reinforce_criterion(pred_G, target_.cuda())\n",
    "                # # measure metrics and record loss\n",
    "                # m1 = metric1(cls_out.cpu(), target)\n",
    "                # m2 = metric2(cls_out.cpu(), target)\n",
    "                history['loss'].append(loss)\n",
    "                self.actor_optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.actor_optimizer.step()\n",
    "                if DEBUG: print(f\"Latest Loss:{history['loss'][-1]}\")\n",
    "        return history\n",
    "\n",
    "    def evaluate_policy(self, env):\n",
    "        # TODO: Compute Accumulative trajectory reward(set a trajectory length threshold if you want)\n",
    "        \"\"\" compute rewards\n",
    "        \"\"\"\n",
    "        self.actor.eval()\n",
    "        _, _, r, _ = self.generate_episode(env, render=False)\n",
    "        rtot = np.sum(np.array(r))\n",
    "        return rtot\n",
    "\n",
    "    def generate_episode(self, env, render=False):\n",
    "        \"\"\"\n",
    "\t\t# Generates an episode by executing the current policy in the given env.\n",
    "\t\t# Returns:\n",
    "\t\t# - a list of states, indexed by time step\n",
    "            shape: (t)\n",
    "\t\t# - a list of actions, indexed by time step\n",
    "            shape: (t, nA)\n",
    "\t\t# - a list of rewards, indexed by time step\n",
    "            shape: (t)\n",
    "        \"\"\"\n",
    "        states, actions, rewards, actions_probs=[], [] ,[], []\n",
    "        # \n",
    "        nS = env.observation_space.shape[0]\n",
    "        nA = env.action_space.n\n",
    "\t\t# Start episode\n",
    "        states.append(np.expand_dims(env.reset(), axis=0))\n",
    "        terminal = False\n",
    "        cts = 0\n",
    "        while not terminal:\n",
    "            cts+=1\n",
    "            if render: \n",
    "                env.unwrapped.render()    # env.render(mode='rgb_array')\n",
    "                env.capture_frame()\n",
    "            ac = self.actor(torch.Tensor(states[-1]).to(device)).squeeze(0)   # ensure [nA] vector\n",
    "            if DEBUG: print(f\"Input state:{states[-1]}\\nOutput action:{ac}\")\n",
    "            ac_prob = ac.detach().cpu().numpy().flatten()\n",
    "            ac_prob = np.nan_to_num(ac_prob,0)\n",
    "            #\n",
    "            a_ = np.random.choice(ac_prob, p=ac_prob)   # stochastic choice\n",
    "            curr_ac = np.where(ac_prob==a_)[0][0]  # Current Action\n",
    "            action_OH = np.eye(nA)[curr_ac]  # one-hot action\n",
    "            \n",
    "            # move in direction and get environment output\n",
    "            s, r, terminal, _ = env.step(curr_ac)\n",
    "            # add to history\n",
    "            states.append(np.expand_dims(s, axis=0))\n",
    "            actions.append(action_OH)\n",
    "            actions_probs.append(ac_prob)\n",
    "            rewards.append(r)\n",
    "            curr_state = copy.deepcopy(s)\n",
    "        if DEBUG: print(f\"action probs:{ac_prob}\\nfinal action:{action_OH}\")\n",
    "        print(\"Finished after {} timesteps\".format(cts+1))\n",
    "\t\t# flatten \n",
    "        states=np.reshape(np.array(states), (-1, nS))\n",
    "        actions=np.reshape(np.array(actions), (-1, nA))\n",
    "        return np.stack(states), np.stack(actions), np.stack(rewards), np.stack(actions_probs)\n",
    "\n",
    "    def train(self, env, gamma=0.99, n=10, render=True):\n",
    "        \"\"\"\n",
    "        # Trains the model on a single episode using REINFORCE or A2C/A3C.\n",
    "        params:\n",
    "            n: number of n-steps look ahead\n",
    "        \"\"\"\n",
    "        # TODO: Implement this method. It may be helpful to call the class\n",
    "        #       method generate_episode() to generate training data.\n",
    "        eps_lim = 500    # length of episode 'limit'\n",
    "        batch_size_ratio = 1    # portion of length of states to feed in NN\n",
    "        alpha = 1e-2\n",
    "        assert 0<batch_size_ratio<=1, \"Batch size between 0 and 1\"\n",
    "        #\n",
    "        env = wrap_env(env)\n",
    "        mean_total, std_total = [], []\n",
    "        # generate episode\n",
    "        states, actions, rewards, actions_prob = self.generate_episode(env, render=render)\n",
    "        states = states[:-1]   # remove the last state\n",
    "        # get discounted reward vector\n",
    "            # [sum : r*gamma*0...r*gamma*n]\n",
    "        G_tot=[0]\n",
    "        for n_gamma, r in enumerate(reversed(rewards)):\n",
    "            # insert from last reward to beginning \n",
    "            G_tot.insert(0, r+gamma**n_gamma*G_tot[0])\n",
    "        if DEBUG: print(f\"Sum of Expected Rewards G:{G_tot}\")\n",
    "        G_tot=np.array(G_tot[:-1])\n",
    "        # weight actions by rewards and fit model\n",
    "        if DEBUG: print(f\"G_tot:[{len(G_tot)}], actions:[{len(actions)}], states:[{len(states)}]\")\n",
    "        G_total_actions = np.multiply(G_tot, actions.T).T   # (t, nA)\n",
    "        train_history = self.fit_actor(torch.Tensor(states), torch.Tensor(G_total_actions*alpha), epochs=1, batch_size=int(len(states)*batch_size_ratio))\n",
    "        return train_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqrh5P-cCbe3"
   },
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "xKD2PlR3WJii"
   },
   "outputs": [],
   "source": [
    "import argparse, matplotlib.pyplot as plt, tqdm\n",
    "def parse_a2c_arguments():\n",
    "    # Command-line flags are defined here.\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--env-name', dest='env_name', type=str,\n",
    "                        default='CartPole-v0', help=\"Name of the environment to be run.\")   # 'LunarLander-v2'\n",
    "    parser.add_argument('--num-episodes', dest='num_episodes', type=int,\n",
    "                        default=10, help=\"Number of episodes to train on.\")    # 3500\n",
    "    parser.add_argument('--lr', dest='lr', type=float,\n",
    "                        default=5e-4, help=\"The actor's learning rate.\")\n",
    "    parser.add_argument('--baseline-lr', dest='baseline_lr', type=float,\n",
    "                        default=5e-4, help=\"The actor's learning rate.\")\n",
    "    parser.add_argument('--critic-lr', dest='critic_lr', type=float,\n",
    "                        default=1e-4, help=\"The critic's learning rate.\")\n",
    "    parser.add_argument('--n', dest='n', type=int,\n",
    "                        default=100, help=\"The value of N in N-step A2C.\")\n",
    "\n",
    "    parser_group = parser.add_mutually_exclusive_group(required=False)\n",
    "    parser_group.add_argument('--render', dest='render',\n",
    "                              action='store_true',\n",
    "                              help=\"Whether to render the environment.\")\n",
    "    parser_group.add_argument('--no-render', dest='render',\n",
    "                              action='store_false',\n",
    "                              help=\"Whether to render the environment.\")\n",
    "    parser.set_defaults(render=False)\n",
    "\n",
    "    return parser.parse_known_args()[0]    #.parse_args()\n",
    "args = parse_a2c_arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Zj2YirE8nIB",
    "outputId": "e4a6e959-5eab-4606-9037-887c8f73b36f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda\\Anaconda3\\envs\\ptml\\lib\\site-packages\\gym\\wrappers\\record_video.py:41: UserWarning: \u001b[33mWARN: Overwriting existing videos at C:\\Users\\Mo\\OneDrive\\Notes\\CMU\\10703 - Deep RL\\F22_10703_Homework_2\\hw2_code\\pytorch\\video folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurations:Namespace(baseline_lr=0.0005, critic_lr=0.0001, env_name='CartPole-v0', lr=0.0005, n=100, num_episodes=1, render=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                       | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0\n",
      "Finished after 14 timesteps\n",
      "[Policy Evaluation]\n",
      "Finished after 13 timesteps\n",
      "Finished after 14 timesteps\n",
      "Finished after 26 timesteps\n",
      "Finished after 22 timesteps\n",
      "Finished after 11 timesteps\n",
      "Finished after 12 timesteps\n",
      "Finished after 18 timesteps\n",
      "Finished after 14 timesteps\n",
      "Finished after 35 timesteps\n",
      "Finished after 14 timesteps\n",
      "Finished after 21 timesteps\n",
      "Finished after 27 timesteps\n",
      "Finished after 19 timesteps\n",
      "Finished after 17 timesteps\n",
      "Finished after 14 timesteps\n",
      "Finished after 13 timesteps\n",
      "Finished after 21 timesteps\n",
      "Finished after 24 timesteps\n",
      "Finished after 17 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished after 13 timesteps\n",
      "The test reward for episode 0 is 17.25 with sd of 6.040488390850528.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#def main_a2c(args):\n",
    "# Parse command-line arguments.\n",
    "env_name = args.env_name\n",
    "\n",
    "# Create the environment.\n",
    "env =  wrap_env(gym.make(env_name))\n",
    "nA = env.action_space.n\n",
    "nS = env.observation_space.shape[0]\n",
    "print(f\"Configurations:{args}\")\n",
    "\n",
    "# Plot average performance of 5 trials\n",
    "num_seeds = 1   # 5\n",
    "l = args.num_episodes//100\n",
    "res = np.zeros((num_seeds, l))\n",
    "\n",
    "gamma = 0.99\n",
    "act_layer = torch.nn.Softmax(dim=1) \n",
    "for i in tqdm.tqdm(range(num_seeds)):\n",
    "    reward_means = []\n",
    "\n",
    "    # TODO: create networks and setup reinforce/a2c\n",
    "    history = dict.fromkeys(['train','test'],[])\n",
    "    actor = NeuralNet(input_size=nS, output_size=nA, activation=act_layer)\n",
    "    critic = NeuralNet(input_size=nS, output_size=nA, activation=act_layer)\n",
    "    A2C_net = A2C(actor=actor, actor_lr=args.lr, N=args.n, nA=nA, \n",
    "                critic=critic, critic_lr=args.critic_lr, baseline=False, a2c=False)\n",
    "    for m in range(args.num_episodes):\n",
    "        print(\"Episode: {}\".format(m))\n",
    "        history['train'].append(A2C_net.train(env, gamma=gamma, render=args.render))\n",
    "        if m % 100 == 0:\n",
    "            print(\"[Policy Evaluation]\")\n",
    "            G = np.zeros(20)   # save 20 iterations of evaluation \n",
    "            for k in range(20):\n",
    "                g = A2C_net.evaluate_policy(env)\n",
    "                G[k] = g\n",
    "            reward_mean = G.mean()\n",
    "            reward_sd = G.std()\n",
    "            print(\"The test reward for episode {0} is {1} with sd of {2}.\".format(m, reward_mean, reward_sd))\n",
    "            reward_means.append(reward_mean)\n",
    "            history['test'].append(G)\n",
    "    res[i] = np.array(reward_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOpUlEQVR4nO3cf6jd9X3H8eeruTRrEUyi8UeN2bVVGHGDFg5K2QauaoyDNtL6h90fDVtL/lj9Y5VCUxzT2v6hbp2ltNsIbSEIa3SO0kApEm2FMYb1xDrarE1zjS0mVZuaIDipkvW9P+7X7Xg5Mffec+49OX6eDzjc8/1+P/fe98cLeeac742pKiRJ7XrbpAeQJE2WIZCkxhkCSWqcIZCkxhkCSWrczKQHWI7zzz+/ZmdnJz2GJE2VAwcO/LqqNi48P5UhmJ2dpd/vT3oMSZoqSX4x7LxvDUlS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS48YSgiTbkhxKMpdk15Dra5M80F1/PMnsguubk7yc5NPjmEeStHgjhyDJGuCrwI3AFuCjSbYsWPZx4GRVXQ7cB9yz4PrfA98ddRZJ0tKN4xXBVcBcVR2pqteAvcD2BWu2A3u65w8B1yYJQJKbgGeAg2OYRZK0ROMIwSXAswPHR7tzQ9dU1SngJeC8JOcAnwE+d6ZvkmRnkn6S/vHjx8cwtiQJJn+z+E7gvqp6+UwLq2p3VfWqqrdx48aVn0ySGjEzhq9xDLh04HhTd27YmqNJZoBzgReBq4Gbk9wLrAN+m+Q3VfWVMcwlSVqEcYTgCeCKJJcx/wf+LcCfLVizD9gB/AdwM/C9qirgj19fkORO4GUjIEmra+QQVNWpJLcCDwNrgG9U1cEkdwH9qtoHfB24P8kccIL5WEiSzgKZ/4v5dOn1etXv9yc9hiRNlSQHqqq38PykbxZLkibMEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS48YSgiTbkhxKMpdk15Dra5M80F1/PMlsd/76JAeS/Kj7+IFxzCNJWryRQ5BkDfBV4EZgC/DRJFsWLPs4cLKqLgfuA+7pzv8a+GBV/QGwA7h/1HkkSUszjlcEVwFzVXWkql4D9gLbF6zZDuzpnj8EXJskVfXDqvpld/4g8I4ka8cwkyRpkcYRgkuAZweOj3bnhq6pqlPAS8B5C9Z8BHiyql4dw0ySpEWamfQAAEmuZP7toq1vsmYnsBNg8+bNqzSZJL31jeMVwTHg0oHjTd25oWuSzADnAi92x5uAbwEfq6qnT/dNqmp3VfWqqrdx48YxjC1JgvGE4AngiiSXJXk7cAuwb8GafczfDAa4GfheVVWSdcB3gF1V9e9jmEWStEQjh6B7z/9W4GHgJ8CDVXUwyV1JPtQt+zpwXpI54Dbg9V8xvRW4HPibJE91jwtGnUmStHipqknPsGS9Xq/6/f6kx5CkqZLkQFX1Fp73XxZLUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuPGEoIk25IcSjKXZNeQ62uTPNBdfzzJ7MC1z3bnDyW5YRzzSJIWb+QQJFkDfBW4EdgCfDTJlgXLPg6crKrLgfuAe7rP3QLcAlwJbAP+oft6kqRVMo5XBFcBc1V1pKpeA/YC2xes2Q7s6Z4/BFybJN35vVX1alU9A8x1X0+StErGEYJLgGcHjo9254auqapTwEvAeYv8XACS7EzST9I/fvz4GMaWJMEU3Syuqt1V1auq3saNGyc9jiS9ZYwjBMeASweON3Xnhq5JMgOcC7y4yM+VJK2gcYTgCeCKJJcleTvzN3/3LVizD9jRPb8Z+F5VVXf+lu63ii4DrgB+MIaZJEmLNDPqF6iqU0luBR4G1gDfqKqDSe4C+lW1D/g6cH+SOeAE87GgW/cg8F/AKeCTVfU/o84kSVq8zP/FfLr0er3q9/uTHkOSpkqSA1XVW3h+am4WS5JWhiGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMaNFIIkG5LsT3K4+7j+NOt2dGsOJ9nRnXtnku8k+WmSg0nuHmUWSdLyjPqKYBfwaFVdATzaHb9Bkg3AHcDVwFXAHQPB+Luq+j3gfcAfJrlxxHkkSUs0agi2A3u653uAm4asuQHYX1UnquoksB/YVlWvVNX3AarqNeBJYNOI80iSlmjUEFxYVc91z58HLhyy5hLg2YHjo925/5NkHfBB5l9VSJJW0cyZFiR5BLhoyKXbBw+qqpLUUgdIMgN8E/hyVR15k3U7gZ0AmzdvXuq3kSSdxhlDUFXXne5akheSXFxVzyW5GPjVkGXHgGsGjjcBjw0c7wYOV9WXzjDH7m4tvV5vycGRJA036ltD+4Ad3fMdwLeHrHkY2JpkfXeTeGt3jiRfAM4F/mrEOSRJyzRqCO4Grk9yGLiuOyZJL8nXAKrqBPB54InucVdVnUiyifm3l7YATyZ5KsknRpxHkrREqZq+d1l6vV71+/1JjyFJUyXJgarqLTzvvyyWpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMaNFIIkG5LsT3K4+7j+NOt2dGsOJ9kx5Pq+JD8eZRZJ0vKM+opgF/BoVV0BPNodv0GSDcAdwNXAVcAdg8FI8mHg5RHnkCQt06gh2A7s6Z7vAW4asuYGYH9Vnaiqk8B+YBtAknOA24AvjDiHJGmZRg3BhVX1XPf8eeDCIWsuAZ4dOD7anQP4PPBF4JUzfaMkO5P0k/SPHz8+wsiSpEEzZ1qQ5BHgoiGXbh88qKpKUov9xkneC7ynqj6VZPZM66tqN7AboNfrLfr7SJLe3BlDUFXXne5akheSXFxVzyW5GPjVkGXHgGsGjjcBjwHvB3pJft7NcUGSx6rqGiRJq2bUt4b2Aa//FtAO4NtD1jwMbE2yvrtJvBV4uKr+sareVVWzwB8BPzMCkrT6Rg3B3cD1SQ4D13XHJOkl+RpAVZ1g/l7AE93jru6cJOkskKrpe7u91+tVv9+f9BiSNFWSHKiq3sLz/stiSWqcIZCkxhkCSWqcIZCkxhkCSWqcIZCkxhkCSWqcIZCkxhkCSWqcIZCkxhkCSWqcIZCkxhkCSWqcIZCkxhkCSWqcIZCkxhkCSWqcIZCkxhkCSWqcIZCkxhkCSWqcIZCkxhkCSWqcIZCkxqWqJj3DkiU5Dvxi0nMs0fnAryc9xCpzz21wz9Pjd6tq48KTUxmCaZSkX1W9Sc+xmtxzG9zz9POtIUlqnCGQpMYZgtWze9IDTIB7boN7nnLeI5CkxvmKQJIaZwgkqXGGYIySbEiyP8nh7uP606zb0a05nGTHkOv7kvx45Sce3Sh7TvLOJN9J8tMkB5PcvbrTL02SbUkOJZlLsmvI9bVJHuiuP55kduDaZ7vzh5LcsKqDj2C5e05yfZIDSX7UffzAqg+/DKP8jLvrm5O8nOTTqzb0OFSVjzE9gHuBXd3zXcA9Q9ZsAI50H9d3z9cPXP8w8M/Ajye9n5XeM/BO4E+6NW8H/g24cdJ7Os0+1wBPA+/uZv1PYMuCNX8J/FP3/Bbgge75lm79WuCy7uusmfSeVnjP7wPe1T3/feDYpPezkvsduP4Q8C/Apye9n6U8fEUwXtuBPd3zPcBNQ9bcAOyvqhNVdRLYD2wDSHIOcBvwhZUfdWyWveeqeqWqvg9QVa8BTwKbVn7kZbkKmKuqI92se5nf+6DB/xYPAdcmSXd+b1W9WlXPAHPd1zvbLXvPVfXDqvpld/4g8I4ka1dl6uUb5WdMkpuAZ5jf71QxBON1YVU91z1/HrhwyJpLgGcHjo925wA+D3wReGXFJhy/UfcMQJJ1wAeBR1dgxnE44x4G11TVKeAl4LxFfu7ZaJQ9D/oI8GRVvbpCc47Lsvfb/SXuM8DnVmHOsZuZ9ADTJskjwEVDLt0+eFBVlWTRv5ub5L3Ae6rqUwvfd5y0ldrzwNefAb4JfLmqjixvSp2NklwJ3ANsnfQsK+xO4L6qerl7gTBVDMESVdV1p7uW5IUkF1fVc0kuBn41ZNkx4JqB403AY8D7gV6SnzP/c7kgyWNVdQ0TtoJ7ft1u4HBVfWn0aVfMMeDSgeNN3blha452cTsXeHGRn3s2GmXPJNkEfAv4WFU9vfLjjmyU/V4N3JzkXmAd8Nskv6mqr6z41OMw6ZsUb6UH8Le88cbpvUPWbGD+fcT13eMZYMOCNbNMz83ikfbM/P2QfwXeNum9nGGfM8zf5L6M/7+ReOWCNZ/kjTcSH+yeX8kbbxYfYTpuFo+y53Xd+g9Peh+rsd8Fa+5kym4WT3yAt9KD+fdGHwUOA48M/GHXA742sO4vmL9hOAf8+ZCvM00hWPaemf8bVwE/AZ7qHp+Y9J7eZK9/CvyM+d8sub07dxfwoe757zD/GyNzwA+Adw987u3d5x3iLP3NqHHuGfhr4L8Hfq5PARdMej8r+TMe+BpTFwL/FxOS1Dh/a0iSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGve/5wv9yACcdLkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ks = np.arange(l)*100\n",
    "avs = np.mean(res, axis=0)\n",
    "maxs = np.max(res, axis=0)\n",
    "mins = np.min(res, axis=0)\n",
    "\n",
    "plt.fill_between(ks, mins, maxs, alpha=0.1)\n",
    "plt.plot(ks, avs, '-o', markersize=1)\n",
    "\n",
    "plt.xlabel('Episode', fontsize = 15)\n",
    "plt.ylabel('Return', fontsize = 15)\n",
    "\n",
    "if not os.path.exists('./plots'):\n",
    "    os.mkdir('./plots')\n",
    "\n",
    "if A2C_net.type == 'A2C':\n",
    "    plt.title(\"A2C Learning Curve for N = {}\".format(args.n), fontsize = 24)\n",
    "    plt.savefig(\"./plots/a2c_curve_N={}.png\".format(args.n))\n",
    "elif A2C_net.type == 'Baseline':\n",
    "    plt.title(\"Baseline Reinforce Learning Curve\".format(args.n), fontsize = 24)\n",
    "    plt.savefig(\"./plots/Baseline_Reinforce_curve.png\".format(args.n))\n",
    "else: # Reinforce\n",
    "    plt.title(\"Reinforce Learning Curve\", fontsize = 24)\n",
    "    plt.savefig(\"./plots/Reinforce_curve.png\")   plt.plot(res)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python [conda env:ptml]",
   "language": "python",
   "name": "conda-env-ptml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
